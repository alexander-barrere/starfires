{"ast":null,"code":"var _jsxFileName = \"/Users/dn5v/.bin/git/github/gpt-pilot/workspace/starfires_v2/starfires_v2_frontend/src/pages/LiveStream.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst LiveStream = () => {\n  _s();\n  const videoRef = useRef(null);\n  useEffect(() => {\n    // Access the user's media\n    const getMedia = async () => {\n      try {\n        const stream = await navigator.mediaDevices.getUserMedia({\n          video: true,\n          audio: true\n        });\n        if (videoRef.current) {\n          videoRef.current.srcObject = stream;\n        }\n\n        // Here you would set up signaling for WebRTC using your chosen method (WebSocket, Socket.IO, etc.)\n        // This would include creating an offer, handling answers, and exchanging ICE candidates.\n        // Example: socket.emit('create or join', room);\n        // You would also set up listeners for the signaling server's messages to handle offers, answers, and ICE candidates.\n      } catch (error) {\n        console.error('Error accessing media devices:', error);\n      }\n    };\n    getMedia();\n\n    // Cleanup function to stop the media stream\n    return () => {\n      if (videoRef.current && videoRef.current.srcObject) {\n        const tracks = videoRef.current.srcObject.getTracks();\n        tracks.forEach(track => track.stop());\n        videoRef.current.srcObject = null;\n      }\n    };\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"live-stream\",\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      playsInline: true,\n      muted: true\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 39,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 38,\n    columnNumber: 9\n  }, this);\n};\n_s(LiveStream, \"PdMsmLAy5JKU3vCrhAlqGYQfKuA=\");\n_c = LiveStream;\nexport default LiveStream;\nvar _c;\n$RefreshReg$(_c, \"LiveStream\");","map":{"version":3,"names":["React","useEffect","useRef","jsxDEV","_jsxDEV","LiveStream","_s","videoRef","getMedia","stream","navigator","mediaDevices","getUserMedia","video","audio","current","srcObject","error","console","tracks","getTracks","forEach","track","stop","className","children","ref","autoPlay","playsInline","muted","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/dn5v/.bin/git/github/gpt-pilot/workspace/starfires_v2/starfires_v2_frontend/src/pages/LiveStream.js"],"sourcesContent":["import React, { useEffect, useRef } from 'react';\n\nconst LiveStream = () => {\n    const videoRef = useRef(null);\n\n    useEffect(() => {\n        // Access the user's media\n        const getMedia = async () => {\n            try {\n                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n                if (videoRef.current) {\n                    videoRef.current.srcObject = stream;\n                }\n\n                // Here you would set up signaling for WebRTC using your chosen method (WebSocket, Socket.IO, etc.)\n                // This would include creating an offer, handling answers, and exchanging ICE candidates.\n                // Example: socket.emit('create or join', room);\n                // You would also set up listeners for the signaling server's messages to handle offers, answers, and ICE candidates.\n\n            } catch (error) {\n                console.error('Error accessing media devices:', error);\n            }\n        };\n\n        getMedia();\n\n        // Cleanup function to stop the media stream\n        return () => {\n            if (videoRef.current && videoRef.current.srcObject) {\n                const tracks = videoRef.current.srcObject.getTracks();\n                tracks.forEach(track => track.stop());\n                videoRef.current.srcObject = null;\n            }\n        };\n    }, []);\n\n    return (\n        <div className=\"live-stream\">\n            <video ref={videoRef} autoPlay playsInline muted></video>\n            {/* Additional UI elements or controls for the live stream could go here */}\n        </div>\n    );\n};\n\nexport default LiveStream;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEjD,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACrB,MAAMC,QAAQ,GAAGL,MAAM,CAAC,IAAI,CAAC;EAE7BD,SAAS,CAAC,MAAM;IACZ;IACA,MAAMO,QAAQ,GAAG,MAAAA,CAAA,KAAY;MACzB,IAAI;QACA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;UAAEC,KAAK,EAAE,IAAI;UAAEC,KAAK,EAAE;QAAK,CAAC,CAAC;QACtF,IAAIP,QAAQ,CAACQ,OAAO,EAAE;UAClBR,QAAQ,CAACQ,OAAO,CAACC,SAAS,GAAGP,MAAM;QACvC;;QAEA;QACA;QACA;QACA;MAEJ,CAAC,CAAC,OAAOQ,KAAK,EAAE;QACZC,OAAO,CAACD,KAAK,CAAC,gCAAgC,EAAEA,KAAK,CAAC;MAC1D;IACJ,CAAC;IAEDT,QAAQ,CAAC,CAAC;;IAEV;IACA,OAAO,MAAM;MACT,IAAID,QAAQ,CAACQ,OAAO,IAAIR,QAAQ,CAACQ,OAAO,CAACC,SAAS,EAAE;QAChD,MAAMG,MAAM,GAAGZ,QAAQ,CAACQ,OAAO,CAACC,SAAS,CAACI,SAAS,CAAC,CAAC;QACrDD,MAAM,CAACE,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QACrChB,QAAQ,CAACQ,OAAO,CAACC,SAAS,GAAG,IAAI;MACrC;IACJ,CAAC;EACL,CAAC,EAAE,EAAE,CAAC;EAEN,oBACIZ,OAAA;IAAKoB,SAAS,EAAC,aAAa;IAAAC,QAAA,eACxBrB,OAAA;MAAOsB,GAAG,EAAEnB,QAAS;MAACoB,QAAQ;MAACC,WAAW;MAACC,KAAK;IAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAExD,CAAC;AAEd,CAAC;AAAC3B,EAAA,CAxCID,UAAU;AAAA6B,EAAA,GAAV7B,UAAU;AA0ChB,eAAeA,UAAU;AAAC,IAAA6B,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}